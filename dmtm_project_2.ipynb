{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dmtm_project_2.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "owzdnCZJIJqE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xP_f8Gb0DB2z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize as wt\n",
        "from nltk import pos_tag as pt\n",
        "from nltk.corpus import stopwords\n",
        "from stanfordcorenlp import StanfordCoreNLP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lckFtuv8DRwS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nlp = StanfordCoreNLP(r'C:\\Users\\Kashyap\\stanford-corenlp-full-2017-06-09')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6x408bcDUVc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import GRU\n",
        "from keras.layers import MaxoutDense\n",
        "from keras.layers import Activation\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jkMkpyGlDaba",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(\"Project-2_Test_Data/Data-2_test.csv\", sep='\\s*,\\s*')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a07zC0B4DgW-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data1['text'] = data1['text'].apply(lambda x: x.replace(\"[comma]\", ',').replace(\"_\", \" \").strip())\n",
        "\n",
        "data1['aspect_term'] = data1['aspect_term'].apply(lambda x: x.replace(\"[comma]\", ',').replace(\"_\", \" \").strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMKkkJyMDiNr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# removing special chars\n",
        "data1['text'] = data1['text'].apply(lambda x: re.sub('\\W+',' ', x))\n",
        "\n",
        "data1['aspect_term'] = data1['aspect_term'].apply(lambda x: re.sub('\\W+',' ', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIb4DV_PDiHa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "init_pos = []\n",
        "for sent in data1['text']:\n",
        "    init_pos.append(nlp.pos_tag(sent))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAMQ13vrDiE2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sw_set = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wm4Ps_DODiDc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data1['text'] = data1['text'].apply(remove_stopwords)\n",
        "\n",
        "data1['aspect_term'] = data1['aspect_term'].apply(remove_stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYs8mDZBDiAh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pos_mat = []\n",
        "for sent in init_pos:\n",
        "    pos_mat.append([x for x in sent if re.match('\\W+', x[0]) is None and x[0] not in sw_set])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SqmevewGDh9s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 2nd method - more words in the window\n",
        "feat_mat = []\n",
        "pos_feat_mat = []\n",
        "word_mat = []\n",
        "progress = 0\n",
        "prog = 0\n",
        "for row,aspect in zip(pos_mat,data1['aspect_term']):\n",
        "    prog += 1\n",
        "    skip_row = False\n",
        "    left_dist = []\n",
        "    right_dist = []\n",
        "    left_pos = []\n",
        "    right_pos = []\n",
        "    left_word = []\n",
        "    right_word = []\n",
        "    aspect_len = len(aspect.split())\n",
        "    split_aspect = pt(wt(aspect))\n",
        "    for i in range(len(row)):\n",
        "\n",
        "        if row[i][0] == split_aspect[0][0]: \n",
        "        #or (split_aspect[0][0] in row[i][0])): \n",
        "        #and ((row[i+aspect_len-1][0] in split_aspect[aspect_len-1][0]) or (split_aspect[aspect_len-1][0] in row[i+aspect_len-1][0])):\n",
        "            \n",
        "            check = [row[q][0] for q in range(i,i+aspect_len)]\n",
        "            #checking if all the words in aspect term occur together in the sentence (https://stackoverflow.com/a/9623147)\n",
        "            if collections.Counter(check) == collections.Counter(aspect.split()):\n",
        "                skip_row = True #Debug\n",
        "                \n",
        "                window = 10 - aspect_len\n",
        "                left = window // 2 #number of words to traverse left\n",
        "                right = window - left #number of words to traverse right\n",
        "                \n",
        "                l = i-left #index reached after moving left\n",
        "                r = i+aspect_len-1+right #index reached after moving right\n",
        "                \n",
        "                \n",
        "                if l < 0 and r > len(row)-1: #if there are not enough words on left and right\n",
        "                    left += l\n",
        "                    right -= r-len(row)+1\n",
        "                \n",
        "                elif l < 0: #if there are not enough words on left \n",
        "                    if r-l <= len(row)-1:\n",
        "                        right += (-1)*l #take words from right\n",
        "                    else:\n",
        "                        right += len(row) - 1 - r\n",
        "                    left -= (-1)*l\n",
        "                        \n",
        "                elif r > len(row)-1: #if there are not enough words on right \n",
        "                    if l-(r-len(row)+1) >= 0:\n",
        "                        left += r-len(row)+1 #take words from left\n",
        "                    else: \n",
        "                        left += l\n",
        "                    right -= r-len(row)+1\n",
        "                        \n",
        "                #print(left) - Debug\n",
        "                #print(i) - debug \n",
        "                #print(right) - debug\n",
        "                #print(aspect) - debug\n",
        "                \n",
        "                count = 0\n",
        "                j = 1\n",
        "                    \n",
        "                while count < left:\n",
        "                    if row[i-j][0][0].isalnum():\n",
        "                        count += 1\n",
        "                        left_dist.append(-1*count)\n",
        "                        left_pos.append(row[i-j][1])\n",
        "                        left_word.append(row[i-j][0])\n",
        "                    j += 1\n",
        "                    \n",
        "                count = 0\n",
        "                #new_count = 0 \n",
        "                #skips through all aspect terms\n",
        "                j = aspect_len\n",
        "            \n",
        "                while count < right:\n",
        "                    if row[i+j][0][0].isalnum() and row[i+j][0] not in split_aspect[0][0]:\n",
        "                        count += 1\n",
        "                        #if new:\n",
        "                        #    right_dist.append(new_count)\n",
        "                        #    new_count += 1\n",
        "                        #else: \n",
        "                        right_dist.append(count)\n",
        "                        right_pos.append(row[i+j][1])\n",
        "                        right_word.append(row[i+j][0])\n",
        "\n",
        "                    if row[i+j][0] in split_aspect[0][0]: #if first word of aspect and current word matches\n",
        "                        if i+j+aspect_len-1 <= len(row)-1: \n",
        "                            check1 = [row[q][0] for q in range(i+j,i+j+aspect_len-1)]\n",
        "                            if collections.Counter(check1) == collections.Counter(aspect.split()):\n",
        "                                j += aspect_len-1\n",
        "                            else:\n",
        "                                count += 1\n",
        "                                right_dist.append(count)\n",
        "                                right_pos.append(row[i+j][1])\n",
        "                                right_word.append(row[i+j][0])\n",
        "                    \n",
        "                        else: \n",
        "                            count += 1\n",
        "                            right_dist.append(count)\n",
        "                            right_pos.append(row[i+j][1])\n",
        "                            right_word.append(row[i+j][0])\n",
        "                                \n",
        "                            #new = True\n",
        "                            #right_dist.append(new_count)\n",
        "                            #right_pos.append(row[i+j][1])\n",
        "                            #right_word.append(row[i+j][0])\n",
        "                            #new_count += 1\n",
        "                            #count += 1    \n",
        "                    j += 1\n",
        "                progress += 1\n",
        "                break\n",
        "                \n",
        "                \n",
        "                \n",
        "    pos_aspect = []\n",
        "    for p in range(len(aspect.split())): \n",
        "        pos_aspect.append(row[i+p][1])\n",
        "    \n",
        "    if skip_row == False:\n",
        "        print(\"{} row not considered in traversal\".format(prog-1))\n",
        "    \n",
        "    rem = 10 - (aspect_len + left + right)\n",
        "    \n",
        "    if aspect_len <= 10:\n",
        "        feat_mat.append([0]*rem + left_dist[::-1] + [0]*len(aspect.split()) + right_dist)\n",
        "        pos_feat_mat.append(['NULL']*rem + left_pos[::-1] + pos_aspect + right_pos)\n",
        "        word_mat.append([0]*rem + left_word[::-1] + aspect.split() + right_word)\n",
        "        \n",
        "    else: \n",
        "        feat_mat.append([0]*rem + left_dist[::-1] + [0]*10 + right_dist)\n",
        "        pos_feat_mat.append(['NULL']*rem + left_pos[::-1] + pos_aspect[:10] + right_pos)\n",
        "        word_mat.append([0]*rem + left_word[::-1] + aspect.split()[:10] + right_word)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1RPE5rFQDhsB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "#Tokenizing distances\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(feat_mat)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "encoded_docs = t.texts_to_sequences(feat_mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8qfmnSADhoU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Creating distance embeddings\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 50, input_length=10)\n",
        "model.add(e)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "dist_embeddings = model.predict(np.array(encoded_docs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TGqCavw2EA6D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Pennington et. al., GloVe: Global Vectors for Word Representation\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove_input_file = 'glove.twitter.27B/glove.twitter.27B.50d.txt'\n",
        "word2vec_output_file = 'glove.twitter.27B/glove.twitter.27B.50d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NjONr8_lEA3n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "# load the Stanford GloVe model\n",
        "filename = 'glove.twitter.27B/glove.twitter.27B.50d.txt.word2vec'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lhLbjZCEA0p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Code taken from Peter Norvig's page http://norvig.com/spell-correct.html\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('big.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RfKpbPc4EAuf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# converting each word into its word embedding\n",
        "zero_mat = np.zeros((50,))\n",
        "glove_emb = []\n",
        "for i,row in enumerate(word_mat): \n",
        "    row_vec = []\n",
        "    for j,word in enumerate(row):\n",
        "        if word == 0:\n",
        "            row_vec.append(zero_mat)\n",
        "        else:\n",
        "            if word in model.vocab:\n",
        "                vec = model.get_vector(word)\n",
        "                row_vec.append(vec)\n",
        "            elif correction(word) in model.vocab:\n",
        "                vec = model.get_vector(correction(word))\n",
        "                row_vec.append(vec)\n",
        "            else:\n",
        "                row_vec.append(zero_mat)\n",
        "    glove_emb.append(np.array(row_vec))\n",
        "\n",
        "glove_emb = np.array(glove_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HHJ32R1lEAoh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sum_embeddings = []\n",
        "for i in range(progress):\n",
        "    row = []\n",
        "    for j in range(10):\n",
        "        temp = dist_embeddings[i,j] + glove_emb[i,j]\n",
        "        row.append(temp)\n",
        "    sum_embeddings.append(np.array(row))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Di_WxsLcEAmh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.array(sum_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VyMtHD0gEAjr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "Y = data1['class']\n",
        "Y = Y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwElSeAPMYKi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1becfd4f-cf65-4a9b-f083-9a59fa7f9e76",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525661983545,
          "user_tz": 300,
          "elapsed": 544,
          "user": {
            "displayName": "Kashyap Desai",
            "photoUrl": "//lh3.googleusercontent.com/-PPr3BdGrk7A/AAAAAAAAAAI/AAAAAAAAAqA/h4Zq31mzOD4/s50-c-k-no/photo.jpg",
            "userId": "102066520271319416296"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Deep learning model \n",
        "model = Sequential()\n",
        "model.add(GRU(100, return_sequences=False, input_shape=(X.shape[1],X.shape[2])))\n",
        "model.add(MaxoutDense(100))\n",
        "model.add(MaxoutDense(3))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:534: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
            "  warnings.warn('The `MaxoutDense` layer is deprecated '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6z_nvyIkNRNq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gshKa6i4NUte",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 4865
        },
        "cellView": "code",
        "outputId": "5b9eb7b5-0547-4361-a8b3-921e877f7a53",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525662381054,
          "user_tz": 300,
          "elapsed": 387436,
          "user": {
            "displayName": "Kashyap Desai",
            "photoUrl": "//lh3.googleusercontent.com/-PPr3BdGrk7A/AAAAAAAAAAI/AAAAAAAAAqA/h4Zq31mzOD4/s50-c-k-no/photo.jpg",
            "userId": "102066520271319416296"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "skf = KFold(n_splits=10)\n",
        "skf.get_n_splits(X, Y)\n",
        "acc = []\n",
        "pre = []\n",
        "rec = []\n",
        "f1 = []\n",
        "for train_index, test_index in skf.split(X, Y):\n",
        "    \n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = Y[train_index], Y[test_index]\n",
        "    model.fit(X_train,y_train,epochs=14)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc.append(accuracy_score(y_test, y_pred.round()))\n",
        "    f1.append(f1_score(y_test, y_pred.round(), average=None))\n",
        "    pre.append(precision_score(y_test, y_pred.round(),average=None))\n",
        "    rec.append(recall_score(y_test, y_pred.round(),average=None))\n",
        "    \n",
        "print(\"Average accuracy\", sum(acc)/len(acc))\n",
        "print(\"Average precision\", np.mean(pre, axis=0))\n",
        "print(\"Average recall\", np.mean(rec, axis=0))\n",
        "print(\"Average f1\", np.mean(f1, axis=0))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/14\n",
            "3241/3241 [==============================] - 4s 1ms/step - loss: 0.5040 - acc: 0.7621\n",
            "Epoch 2/14\n",
            "3241/3241 [==============================] - 3s 852us/step - loss: 0.4503 - acc: 0.7917\n",
            "Epoch 3/14\n",
            "3241/3241 [==============================] - 3s 860us/step - loss: 0.4306 - acc: 0.8071\n",
            "Epoch 4/14\n",
            "3241/3241 [==============================] - 3s 848us/step - loss: 0.4108 - acc: 0.8164\n",
            "Epoch 5/14\n",
            "3241/3241 [==============================] - 3s 846us/step - loss: 0.3911 - acc: 0.8272\n",
            "Epoch 6/14\n",
            "3200/3241 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8382"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3241/3241 [==============================] - 3s 837us/step - loss: 0.3687 - acc: 0.8381\n",
            "Epoch 7/14\n",
            "3241/3241 [==============================] - 3s 839us/step - loss: 0.3453 - acc: 0.8477\n",
            "Epoch 8/14\n",
            "3241/3241 [==============================] - 3s 847us/step - loss: 0.3254 - acc: 0.8604\n",
            "Epoch 9/14\n",
            "3241/3241 [==============================] - 3s 858us/step - loss: 0.3027 - acc: 0.8698\n",
            "Epoch 10/14\n",
            "3241/3241 [==============================] - 3s 856us/step - loss: 0.2821 - acc: 0.8800\n",
            "Epoch 11/14\n",
            "3241/3241 [==============================] - 3s 847us/step - loss: 0.2621 - acc: 0.8874\n",
            "Epoch 12/14\n",
            " 224/3241 [=>............................] - ETA: 2s - loss: 0.2413 - acc: 0.8884"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3241/3241 [==============================] - 3s 848us/step - loss: 0.2463 - acc: 0.8927\n",
            "Epoch 13/14\n",
            "3241/3241 [==============================] - 3s 847us/step - loss: 0.2260 - acc: 0.9018\n",
            "Epoch 14/14\n",
            "3241/3241 [==============================] - 3s 852us/step - loss: 0.2073 - acc: 0.9121\n",
            "Epoch 1/14\n",
            "3241/3241 [==============================] - 3s 852us/step - loss: 0.2394 - acc: 0.8993\n",
            "Epoch 2/14\n",
            "3241/3241 [==============================] - 3s 833us/step - loss: 0.2129 - acc: 0.9113\n",
            "Epoch 3/14\n",
            "3241/3241 [==============================] - 3s 862us/step - loss: 0.1976 - acc: 0.9171\n",
            "Epoch 4/14\n",
            " 224/3241 [=>............................] - ETA: 2s - loss: 0.1723 - acc: 0.9226"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3241/3241 [==============================] - 3s 848us/step - loss: 0.1863 - acc: 0.9191\n",
            "Epoch 5/14\n",
            "3241/3241 [==============================] - 3s 840us/step - loss: 0.1717 - acc: 0.9264\n",
            "Epoch 6/14\n",
            "3241/3241 [==============================] - 3s 842us/step - loss: 0.1669 - acc: 0.9286\n",
            "Epoch 7/14\n",
            "3241/3241 [==============================] - 3s 840us/step - loss: 0.1531 - acc: 0.9335\n",
            "Epoch 8/14\n",
            "3241/3241 [==============================] - 3s 843us/step - loss: 0.1513 - acc: 0.9360\n",
            "Epoch 9/14\n",
            "3241/3241 [==============================] - 3s 837us/step - loss: 0.1480 - acc: 0.9351\n",
            "Epoch 10/14\n",
            " 224/3241 [=>............................] - ETA: 2s - loss: 0.1373 - acc: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3241/3241 [==============================] - 3s 845us/step - loss: 0.1431 - acc: 0.9370\n",
            "Epoch 11/14\n",
            "3241/3241 [==============================] - 3s 850us/step - loss: 0.1389 - acc: 0.9392\n",
            "Epoch 12/14\n",
            "3241/3241 [==============================] - 3s 833us/step - loss: 0.1304 - acc: 0.9402\n",
            "Epoch 13/14\n",
            "3241/3241 [==============================] - 3s 848us/step - loss: 0.1305 - acc: 0.9430\n",
            "Epoch 14/14\n",
            "3241/3241 [==============================] - 3s 837us/step - loss: 0.1253 - acc: 0.9433\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 825us/step - loss: 0.1430 - acc: 0.9374\n",
            "Epoch 2/14\n",
            " 512/3242 [===>..........................] - ETA: 2s - loss: 0.0972 - acc: 0.9603"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 853us/step - loss: 0.1353 - acc: 0.9366\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 845us/step - loss: 0.1337 - acc: 0.9382\n",
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 846us/step - loss: 0.1330 - acc: 0.9387\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 835us/step - loss: 0.1295 - acc: 0.9386\n",
            "Epoch 6/14\n",
            "3242/3242 [==============================] - 3s 841us/step - loss: 0.1232 - acc: 0.9429\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 828us/step - loss: 0.1242 - acc: 0.9429\n",
            "Epoch 8/14\n",
            " 256/3242 [=>............................] - ETA: 2s - loss: 0.0811 - acc: 0.9661"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 829us/step - loss: 0.1212 - acc: 0.9407\n",
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 836us/step - loss: 0.1200 - acc: 0.9449\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 831us/step - loss: 0.1225 - acc: 0.9423\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 835us/step - loss: 0.1179 - acc: 0.9430\n",
            "Epoch 12/14\n",
            "3242/3242 [==============================] - 3s 837us/step - loss: 0.1149 - acc: 0.9413\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 821us/step - loss: 0.1116 - acc: 0.9453\n",
            "Epoch 14/14\n",
            " 352/3242 [==>...........................] - ETA: 2s - loss: 0.0985 - acc: 0.9602"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.1134 - acc: 0.9443\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 838us/step - loss: 0.1100 - acc: 0.9430\n",
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 834us/step - loss: 0.1078 - acc: 0.9480\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 826us/step - loss: 0.1064 - acc: 0.9478\n",
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 826us/step - loss: 0.1047 - acc: 0.9479\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 838us/step - loss: 0.0993 - acc: 0.9493\n",
            "Epoch 6/14\n",
            " 608/3242 [====>.........................] - ETA: 2s - loss: 0.0864 - acc: 0.9589"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.1033 - acc: 0.9479\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 840us/step - loss: 0.1012 - acc: 0.9473\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.0983 - acc: 0.9485\n",
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 841us/step - loss: 0.1003 - acc: 0.9470\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 841us/step - loss: 0.0977 - acc: 0.9482\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0955 - acc: 0.9517\n",
            "Epoch 12/14\n",
            " 160/3242 [>.............................] - ETA: 2s - loss: 0.0670 - acc: 0.9646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 836us/step - loss: 0.0967 - acc: 0.9484\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 835us/step - loss: 0.0952 - acc: 0.9499\n",
            "Epoch 14/14\n",
            "3242/3242 [==============================] - 3s 838us/step - loss: 0.0956 - acc: 0.9514\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 847us/step - loss: 0.0967 - acc: 0.9496\n",
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 837us/step - loss: 0.0921 - acc: 0.9515\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 837us/step - loss: 0.0939 - acc: 0.9514\n",
            "Epoch 4/14\n",
            " 416/3242 [==>...........................] - ETA: 2s - loss: 0.0498 - acc: 0.9784"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 838us/step - loss: 0.0923 - acc: 0.9529\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 834us/step - loss: 0.0904 - acc: 0.9492\n",
            "Epoch 6/14\n",
            "3242/3242 [==============================] - 3s 841us/step - loss: 0.0887 - acc: 0.9540\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.0877 - acc: 0.9534\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 856us/step - loss: 0.0866 - acc: 0.9550\n",
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 855us/step - loss: 0.0860 - acc: 0.9518\n",
            "Epoch 10/14\n",
            "  32/3242 [..............................] - ETA: 3s - loss: 0.0280 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 863us/step - loss: 0.0853 - acc: 0.9545\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 862us/step - loss: 0.0791 - acc: 0.9586\n",
            "Epoch 12/14\n",
            "3242/3242 [==============================] - 3s 853us/step - loss: 0.0806 - acc: 0.9560\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 869us/step - loss: 0.0771 - acc: 0.9584\n",
            "Epoch 14/14\n",
            "3242/3242 [==============================] - 3s 860us/step - loss: 0.0760 - acc: 0.9590\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 847us/step - loss: 0.0811 - acc: 0.9570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 850us/step - loss: 0.0756 - acc: 0.9601\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 852us/step - loss: 0.0743 - acc: 0.9602\n",
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0702 - acc: 0.9635\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 873us/step - loss: 0.0686 - acc: 0.9652\n",
            "Epoch 6/14\n",
            "3242/3242 [==============================] - 3s 858us/step - loss: 0.0678 - acc: 0.9647\n",
            "Epoch 7/14\n",
            "2912/3242 [=========================>....] - ETA: 0s - loss: 0.0654 - acc: 0.9673"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 868us/step - loss: 0.0658 - acc: 0.9676\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 861us/step - loss: 0.0622 - acc: 0.9677\n",
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 855us/step - loss: 0.0621 - acc: 0.9680\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 851us/step - loss: 0.0586 - acc: 0.9702\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 855us/step - loss: 0.0559 - acc: 0.9730\n",
            "Epoch 12/14\n",
            "3242/3242 [==============================] - 3s 842us/step - loss: 0.0553 - acc: 0.9728\n",
            "Epoch 13/14\n",
            " 256/3242 [=>............................] - ETA: 2s - loss: 0.0399 - acc: 0.9870"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0525 - acc: 0.9751\n",
            "Epoch 14/14\n",
            "3242/3242 [==============================] - 3s 845us/step - loss: 0.0506 - acc: 0.9761\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 848us/step - loss: 0.0506 - acc: 0.9762\n",
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 845us/step - loss: 0.0509 - acc: 0.9770\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0454 - acc: 0.9784\n",
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0465 - acc: 0.9784\n",
            "Epoch 5/14\n",
            " 256/3242 [=>............................] - ETA: 2s - loss: 0.0294 - acc: 0.9883"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 823us/step - loss: 0.0419 - acc: 0.9817\n",
            "Epoch 6/14\n",
            "3242/3242 [==============================] - 3s 839us/step - loss: 0.0436 - acc: 0.9821\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 850us/step - loss: 0.0405 - acc: 0.9823\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 840us/step - loss: 0.0402 - acc: 0.9831\n",
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 850us/step - loss: 0.0434 - acc: 0.9817\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0343 - acc: 0.9833\n",
            "Epoch 11/14\n",
            "  96/3242 [..............................] - ETA: 2s - loss: 0.0068 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 845us/step - loss: 0.0406 - acc: 0.9832\n",
            "Epoch 12/14\n",
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.0350 - acc: 0.9842\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.0350 - acc: 0.9854\n",
            "Epoch 14/14\n",
            "3242/3242 [==============================] - 3s 842us/step - loss: 0.0323 - acc: 0.9864\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 849us/step - loss: 0.0376 - acc: 0.9844\n",
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 853us/step - loss: 0.0366 - acc: 0.9849\n",
            "Epoch 3/14\n",
            "  32/3242 [..............................] - ETA: 3s - loss: 0.0672 - acc: 0.9792"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 853us/step - loss: 0.0334 - acc: 0.9866\n",
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 841us/step - loss: 0.0339 - acc: 0.9860\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 854us/step - loss: 0.0353 - acc: 0.9847\n",
            "Epoch 6/14\n",
            "3242/3242 [==============================] - 3s 845us/step - loss: 0.0346 - acc: 0.9850\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 847us/step - loss: 0.0307 - acc: 0.9861\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 852us/step - loss: 0.0312 - acc: 0.9860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 849us/step - loss: 0.0313 - acc: 0.9869\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 850us/step - loss: 0.0275 - acc: 0.9878\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0309 - acc: 0.9875\n",
            "Epoch 12/14\n",
            "3242/3242 [==============================] - 3s 849us/step - loss: 0.0268 - acc: 0.9883\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 838us/step - loss: 0.0302 - acc: 0.9886\n",
            "Epoch 14/14\n",
            "2944/3242 [==========================>...] - ETA: 0s - loss: 0.0280 - acc: 0.9882"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 847us/step - loss: 0.0274 - acc: 0.9883\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 841us/step - loss: 0.0284 - acc: 0.9874\n",
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 846us/step - loss: 0.0274 - acc: 0.9888\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 854us/step - loss: 0.0243 - acc: 0.9889\n",
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 843us/step - loss: 0.0279 - acc: 0.9880\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 840us/step - loss: 0.0252 - acc: 0.9892\n",
            "Epoch 6/14\n",
            " 480/3242 [===>..........................] - ETA: 2s - loss: 0.0202 - acc: 0.9910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 838us/step - loss: 0.0259 - acc: 0.9893\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 850us/step - loss: 0.0245 - acc: 0.9894\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 844us/step - loss: 0.0241 - acc: 0.9900\n",
            "Epoch 9/14\n",
            "3242/3242 [==============================] - 3s 856us/step - loss: 0.0260 - acc: 0.9893\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 848us/step - loss: 0.0234 - acc: 0.9895\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 866us/step - loss: 0.0237 - acc: 0.9907\n",
            "Epoch 12/14\n",
            "  32/3242 [..............................] - ETA: 2s - loss: 0.0076 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 856us/step - loss: 0.0213 - acc: 0.9911\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 852us/step - loss: 0.0276 - acc: 0.9903\n",
            "Epoch 14/14\n",
            "3242/3242 [==============================] - 3s 855us/step - loss: 0.0185 - acc: 0.9919\n",
            "Epoch 1/14\n",
            "3242/3242 [==============================] - 3s 853us/step - loss: 0.0185 - acc: 0.9927\n",
            "Epoch 2/14\n",
            "3242/3242 [==============================] - 3s 852us/step - loss: 0.0213 - acc: 0.9917\n",
            "Epoch 3/14\n",
            "3242/3242 [==============================] - 3s 860us/step - loss: 0.0172 - acc: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/14\n",
            "3242/3242 [==============================] - 3s 856us/step - loss: 0.0229 - acc: 0.9918\n",
            "Epoch 5/14\n",
            "3242/3242 [==============================] - 3s 862us/step - loss: 0.0181 - acc: 0.9926\n",
            "Epoch 6/14\n",
            "3242/3242 [==============================] - 3s 864us/step - loss: 0.0173 - acc: 0.9933\n",
            "Epoch 7/14\n",
            "3242/3242 [==============================] - 3s 850us/step - loss: 0.0183 - acc: 0.9932\n",
            "Epoch 8/14\n",
            "3242/3242 [==============================] - 3s 860us/step - loss: 0.0190 - acc: 0.9930\n",
            "Epoch 9/14\n",
            "2912/3242 [=========================>....] - ETA: 0s - loss: 0.0156 - acc: 0.9939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3242/3242 [==============================] - 3s 847us/step - loss: 0.0167 - acc: 0.9938\n",
            "Epoch 10/14\n",
            "3242/3242 [==============================] - 3s 853us/step - loss: 0.0189 - acc: 0.9934\n",
            "Epoch 11/14\n",
            "3242/3242 [==============================] - 3s 866us/step - loss: 0.0155 - acc: 0.9949\n",
            "Epoch 12/14\n",
            "3242/3242 [==============================] - 3s 861us/step - loss: 0.0181 - acc: 0.9931\n",
            "Epoch 13/14\n",
            "3242/3242 [==============================] - 3s 851us/step - loss: 0.0160 - acc: 0.9935\n",
            "Epoch 14/14\n",
            "3242/3242 [==============================] - 3s 871us/step - loss: 0.0178 - acc: 0.9935\n",
            "Average accuracy 0.9087650046168051\n",
            "Average precision [0.89936677 0.82702683 0.9612767 ]\n",
            "Average recall [0.8615797  0.85904924 0.93722894]\n",
            "Average f1 [0.8774303  0.83680463 0.94789151]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d8GFwLmew2uN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3b03eeaf-ae22-4ccc-a61e-12d594e30d6c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525011422389,
          "user_tz": 300,
          "elapsed": 247,
          "user": {
            "displayName": "Kashyap Desai",
            "photoUrl": "//lh3.googleusercontent.com/-PPr3BdGrk7A/AAAAAAAAAAI/AAAAAAAAAqA/h4Zq31mzOD4/s50-c-k-no/photo.jpg",
            "userId": "102066520271319416296"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_2 (GRU)                  (None, 100)               45300     \n",
            "_________________________________________________________________\n",
            "maxout_dense_3 (MaxoutDense) (None, 100)               40400     \n",
            "_________________________________________________________________\n",
            "maxout_dense_4 (MaxoutDense) (None, 3)                 1212      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 86,912\n",
            "Trainable params: 86,912\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}